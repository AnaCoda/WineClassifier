{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wine_classification_NN_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MemFGW7ksHC4"
      },
      "source": [
        "# Wine Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PvVbtuzBsHDO",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "plt.style.use('fivethirtyeight')\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmWRNBzKeR4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxVkoOjefKnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change to top directory of your Drive\n",
        "import os\n",
        "os.chdir('/content/gdrive/Shared drives/AI4ALL SFU NLP GROUP 3/WINE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UkOBp_TDsHDj",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "df = pd.read_csv('winemag-data-130k-v2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLqhFuE2sHDp",
        "colab": {}
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wFkPe49b0mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get only the columns we want\n",
        "wine_df = df[['description', 'variety']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsgAm-bEb0mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9UInZWLb0m6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df['variety'].value_counts()[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbs6nCKlb0nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topVarieties = wine_df['variety'].value_counts()[:5].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEERywKRb0nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df_short = wine_df[wine_df.variety.isin(topVarieties)].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acqw3crb0nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df_short"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XgmNcpsb0nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df_short['variety_num'] = wine_df_short['variety'].astype('category').cat.codes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3gLrisgkwTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wineNames = dict( enumerate(wine_df_short['variety'].astype('category').cat.categories ) )\n",
        "wineNames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFU2CyGbb0nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_df_short"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOpWrNk_b0nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split our data into training and test sets (80/20)\n",
        "train_df, test_df = np.split(wine_df_short.sample(frac=1), [int(.8*len(wine_df_short))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w27v8yzTb0nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops = stopwords.words('english')\n",
        "for i in topVarieties:\n",
        "  stops.extend(i.lower().split(' '))\n",
        "print(stops[-15:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvqoXK2fb0ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanText(text):\n",
        "    # Remove new lines from the text\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = text.lower()\n",
        "    text = text.split(' ')\n",
        "    text = [w for w in text if not w in stops] \n",
        "    text = ' '.join(text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3RZou-Sb0nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['description'] = train_df['description'].apply(lambda x : cleanText(x))\n",
        "test_df['description'] = test_df['description'].apply(lambda x : cleanText(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqW9hU61b0nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB2PTVXWb0nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_df['description']\n",
        "y = train_df['variety_num']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgYR8ZUrb0ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 20000\n",
        "max_seq_length = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yELYOGAb0n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a tokenizer using Keras\n",
        "X_tokenizer = text.Tokenizer(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRMPjWAGb0n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the tokenizer on our text\n",
        "X_tokenizer.fit_on_texts(list(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV3DLvilb0oC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode words in sentences as a list of integer sequences\n",
        "X_tokenized = X_tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-sxCZRxb0oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad sentences to maximum sequence length\n",
        "X_train_val = sequence.pad_sequences(X_tokenized, maxlen=max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj1DWfQcb0oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Save our fitted tokenizer for future use\n",
        "# with open('wine_tokenizer.pkl', 'wb') as f:\n",
        "#     pickle.dump(X_tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7etI5clb0oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Download the GloVe embeddings and unzip the file\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl7e2EuPb0oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pre-trained word vectors\n",
        "embedding_dim = 100\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:],dtype='float32')\n",
        "    embeddings_index[word]= coefs\n",
        "f.close()\n",
        "print(f'Found {len(embeddings_index)} word vectors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFB3tCfUb0od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create embedding matrix for our neural network\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, index in X_tokenizer.word_index.items():\n",
        "    if index > vocab_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index]= embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmxrJer0b0og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(np.array(y))\n",
        "\n",
        "'''\n",
        "sigmoid:\n",
        "0.88\n",
        "1\n",
        "\n",
        "softmax:\n",
        "[0.10, 0.35, 0.55] = 1\n",
        "2\n",
        "[0, 0, 1]\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECqyvj43b0ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFRW01LTb0on",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,\n",
        "                    embedding_dim,\n",
        "                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                    trainable=False))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2,\n",
        "                       strides=None,\n",
        "                       padding='same',))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(hidden_dims, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2uXD45b0oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT6xZYZVb0ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of samples processed before the model is updated\n",
        "batch_size= 16\n",
        "# Number of times we go through the entire dataset (forward and backward)\n",
        "epochs = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbkmwxEjb0oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y, test_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZfcJwwib0o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the model\n",
        "hist = model.fit(X_train, y_train,\n",
        "                 batch_size=batch_size,\n",
        "                 epochs=epochs,\n",
        "                 validation_data=(X_val, y_val)\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gt2N0oHK5NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('wine_cnn_5_wines.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Bkfge9c3va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('wine_cnn_5_wines.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcLgyV4FnL31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = test_df['description'].values\n",
        "y_test = test_df['variety_num'].values\n",
        "print(y_test[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6F6bsbSPT9Kv",
        "colab": {}
      },
      "source": [
        "# Encode words in sentences as a list of integer sequences\n",
        "X_test_tokenized = X_tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6_8Rl6QhPJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBEOzzPiT9K9",
        "colab": {}
      },
      "source": [
        "# Pad sentences to maximum sequence length\n",
        "X_test_val = sequence.pad_sequences(X_test_tokenized, maxlen=max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WynpxVBhTDl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8D8Frvjb0o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_pred = model.predict(X_test_val)\n",
        "y_pred = np.argmax(model.predict(X_test_val), axis=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSfmI5zTnVFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(test_df.head(10).description).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgo0HFqOZvQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(y_test[:10])\n",
        "print(y_pred[:10])\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.show(fig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-fsRHocgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGsvcVDqgwzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZEVXy2mnneq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((test_df.head(10).description).tolist())\n",
        "test_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIlhNGtOgANf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wineReview = input(\"Enter a description of what you want your wine to taste like: \")\n",
        "while(wineReview != 'exit'):\n",
        "  wineReview = cleanText(wineReview)\n",
        "  wine_tokenized = X_tokenizer.texts_to_sequences([wineReview])\n",
        "  wine_padded = sequence.pad_sequences(wine_tokenized[0:1], maxlen=max_seq_length)\n",
        "  predictedWine = np.argmax(model.predict(wine_padded), axis=-1)\n",
        "  print(wineNames[int(predictedWine)])\n",
        "  wineReview = input(\"Enter a description of what you want your wine to taste like: \")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}